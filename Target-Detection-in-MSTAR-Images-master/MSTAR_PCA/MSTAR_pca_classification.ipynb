{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xVALNYBurlN"
   },
   "source": [
    "# **SAR Target/Object Detection Using Machine Learning**\n",
    "\n",
    "The notebook represents real time implementation of data processing, model building and testing of multiple Machine Learning Algorithms for detection of the target in MSTAR dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "theArxQJHztH"
   },
   "source": [
    "**Mounting Google Drive for Cloud based Processing using GPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "gxYvd5E0Wj7I",
    "outputId": "2e86c519-19ef-408f-9e6a-fb103e080078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unN2bCKpIDq4"
   },
   "source": [
    "**Necassary Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "GzaMFWkDhmEL",
    "outputId": "b4228afa-8a66-4b24-e17c-68768f1701b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy==1.2.1\n",
      "  Using cached scipy-1.2.1.tar.gz (23.1 MB)\n",
      "Building wheels for collected packages: scipy\n",
      "  Building wheel for scipy (setup.py): started\n",
      "  Building wheel for scipy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for scipy\n",
      "Failed to build scipy\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "    Running setup.py install for scipy: started\n",
      "    Running setup.py install for scipy: finished with status 'error'\n",
      "  Rolling back uninstall of scipy\n",
      "  Moving to d:\\anaconda3\\lib\\site-packages\\scipy-1.5.2.dist-info\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-wheel-bjmwb8r6'\n",
      "       cwd: C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\\n",
      "  Complete output (122 lines):\n",
      "  Running from scipy source directory.\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['D:/Anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "    libraries openblas not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Could not locate executable DF\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  customize G95FCompiler\n",
      "  Could not locate executable g95\n",
      "  customize IntelEM64VisualFCompiler\n",
      "  customize IntelEM64TFCompiler\n",
      "  Could not locate executable efort\n",
      "  Could not locate executable efc\n",
      "  customize PGroupFlangCompiler\n",
      "  Could not locate executable flang\n",
      "  don't know how to compile Fortran code on platform 'nt'\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "    libraries openblas,lapack not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  flame_info:\n",
      "    libraries flame not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries tatlas,tatlas not found in D:\\Anaconda3\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "    libraries tatlas,tatlas not found in D:\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries satlas,satlas not found in D:\\Anaconda3\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "    libraries satlas,satlas not found in D:\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries ptf77blas,ptcblas,atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "    libraries ptf77blas,ptcblas,atlas not found in D:\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries f77blas,cblas,atlas not found in D:\\Anaconda3\\lib\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "    libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "    libraries f77blas,cblas,atlas not found in D:\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "    libraries lapack not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    return getattr(self, '_calc_info_{}'.format(name))()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from D:\\Anaconda3\\Lib\\site-packages\\~cipy-1.5.2.dist-info\n",
      "  Moving to d:\\anaconda3\\lib\\site-packages\\scipy\\\n",
      "   from D:\\Anaconda3\\Lib\\site-packages\\~cipy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    return getattr(self, '_calc_info_{}'.format(name))()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 492, in <module>\n",
      "      setup_package()\n",
      "    File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 488, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "      config = configuration()\n",
      "    File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 395, in configuration\n",
      "      raise NotFoundError(msg)\n",
      "  numpy.distutils.system_info.NotFoundError: No lapack/blas resources found.\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for scipy\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\n",
      "  Complete output (9 lines):\n",
      "  \n",
      "  `setup.py clean` is not supported, use one of the following instead:\n",
      "  \n",
      "    - `git clean -xdf` (cleans all files)\n",
      "    - `git clean -Xdf` (cleans all versioned files, doesn't touch\n",
      "                        files that aren't checked into the git repo)\n",
      "  \n",
      "  Add `--force` to your command to use it anyway if you must (unsupported).\n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for scipy\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-record-qilq3e9t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda3\\Include\\scipy'\n",
      "         cwd: C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\\n",
      "    Complete output (131 lines):\n",
      "    \n",
      "    Note: if you need reliable uninstall behavior, then install\n",
      "    with pip instead of using `setup.py install`:\n",
      "    \n",
      "      - `pip install .`       (from a git repo or downloaded source\n",
      "                               release)\n",
      "      - `pip install scipy`   (last SciPy release on PyPI)\n",
      "    \n",
      "    \n",
      "    Running from scipy source directory.\n",
      "    lapack_opt_info:\n",
      "    lapack_mkl_info:\n",
      "    No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "    customize MSVCCompiler\n",
      "      libraries mkl_rt not found in ['D:/Anaconda3\\\\Library\\\\lib']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_lapack_info:\n",
      "      libraries openblas not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "    get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "    customize GnuFCompiler\n",
      "    Could not locate executable g77\n",
      "    Could not locate executable f77\n",
      "    customize IntelVisualFCompiler\n",
      "    Could not locate executable ifort\n",
      "    Could not locate executable ifl\n",
      "    customize AbsoftFCompiler\n",
      "    Could not locate executable f90\n",
      "    customize CompaqVisualFCompiler\n",
      "    Could not locate executable DF\n",
      "    customize IntelItaniumVisualFCompiler\n",
      "    Could not locate executable efl\n",
      "    customize Gnu95FCompiler\n",
      "    Could not locate executable gfortran\n",
      "    Could not locate executable f95\n",
      "    customize G95FCompiler\n",
      "    Could not locate executable g95\n",
      "    customize IntelEM64VisualFCompiler\n",
      "    customize IntelEM64TFCompiler\n",
      "    Could not locate executable efort\n",
      "    Could not locate executable efc\n",
      "    customize PGroupFlangCompiler\n",
      "    Could not locate executable flang\n",
      "    don't know how to compile Fortran code on platform 'nt'\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_clapack_info:\n",
      "      libraries openblas,lapack not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    flame_info:\n",
      "      libraries flame not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries tatlas,tatlas not found in D:\\Anaconda3\\lib\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "      libraries tatlas,tatlas not found in C:\\\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "      libraries tatlas,tatlas not found in D:\\Anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_info:\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries satlas,satlas not found in D:\\Anaconda3\\lib\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "      libraries satlas,satlas not found in C:\\\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "      libraries satlas,satlas not found in D:\\Anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries ptf77blas,ptcblas,atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "      libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "      libraries ptf77blas,ptcblas,atlas not found in D:\\Anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_info:\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries f77blas,cblas,atlas not found in D:\\Anaconda3\\lib\n",
      "      libraries lapack_atlas not found in C:\\\n",
      "      libraries f77blas,cblas,atlas not found in C:\\\n",
      "      libraries lapack_atlas not found in D:\\Anaconda3\\libs\n",
      "      libraries f77blas,cblas,atlas not found in D:\\Anaconda3\\libs\n",
      "    <class 'numpy.distutils.system_info.atlas_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    accelerate_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    lapack_info:\n",
      "      libraries lapack not found in ['D:\\\\Anaconda3\\\\lib', 'C:\\\\', 'D:\\\\Anaconda3\\\\libs']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "        the LAPACK environment variable.\n",
      "      return getattr(self, '_calc_info_{}'.format(name))()\n",
      "    lapack_src_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\system_info.py:1748: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "        Directories to search for the sources can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "        the LAPACK_SRC environment variable.\n",
      "      return getattr(self, '_calc_info_{}'.format(name))()\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 492, in <module>\n",
      "        setup_package()\n",
      "      File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 488, in setup_package\n",
      "        setup(**metadata)\n",
      "      File \"D:\\Anaconda3\\lib\\site-packages\\numpy\\distutils\\core.py\", line 135, in setup\n",
      "        config = configuration()\n",
      "      File \"C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-install-bpwo_rzc\\scipy\\setup.py\", line 395, in configuration\n",
      "        raise NotFoundError(msg)\n",
      "    numpy.distutils.system_info.NotFoundError: No lapack/blas resources found.\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'D:\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Eric\\\\AppData\\\\Local\\\\Temp\\\\pip-install-bpwo_rzc\\\\scipy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Eric\\AppData\\Local\\Temp\\pip-record-qilq3e9t\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\Anaconda3\\Include\\scipy' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkm_A64Ph1sC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.misc as im\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import resize\n",
    "from skimage import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgEg-TV1h9_t"
   },
   "outputs": [],
   "source": [
    "import PIL #resizing the images\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isTLNXTDyWwP"
   },
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4uLqaMEGCCE"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?export=view&id=11u7TILbn_1a5OvI97Zrv4nzGke8LSC88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGZYIzbCHNWK"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?export=view&id=1LtSjZGAiqjl6UPZYBJjiJupzPyyA6YGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZDCGwImiAOd"
   },
   "outputs": [],
   "source": [
    "def get_mstar_data(stage, width=100, height=100, crop_size=100, aug=False):\n",
    "    data_dir = \"C:/Users/Eric/Desktop/Target-Detection-in-MSTAR-Images-master/train/\" if stage == \"train\" else \"C:/Users/Eric/Desktop/Target-Detection-in-MSTAR-Images-master/test/\" if stage == \"test\" else None\n",
    "    print(\"------ \" + stage + \" ------\")\n",
    "    sub_dir = [\"2S1\", \"SN_132\", \"BRDM_2\", \"BTR_60\", \"SN_9563\", \"D7\", \"T62\", \"SN_C71\", \"ZIL131\", \"ZSU_23_4\"]\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(sub_dir)):\n",
    "        tmp_dir = data_dir + sub_dir[i] + \"/\"\n",
    "        img_idx = [x for x in os.listdir(tmp_dir) if (x.endswith(\".jpg\")or x.endswith(\".JPG\"))]\n",
    "        print(sub_dir[i], len(img_idx))\n",
    "        y += [i] * len(img_idx)\n",
    "        for j in range(len(img_idx)):\n",
    "#             img = im.imresize(im.imread((tmp_dir + img_idx[j])), [height, width])\n",
    "            img = np.array(Image.fromarray(imageio.imread((tmp_dir + img_idx[j]))).resize((height, width)))\n",
    "            img = img[(height - crop_size) // 2 : height - (height - crop_size) // 2, \\\n",
    "                  (width - crop_size) // 2: width - (width - crop_size) // 2]\n",
    "#             print(img)\n",
    "\n",
    "            # img = img[16:112, 16:112]   # crop\n",
    "            X.append(img)\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x='a.JPG'\n",
    "x.endswith(\".jpg\") or x.endswith(\".JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioONgNWqiRrq"
   },
   "outputs": [],
   "source": [
    "def data_shuffle(X, y, seed=0):\n",
    "    data = np.hstack([X, y[:, np.newaxis]])\n",
    "    np.random.shuffle(data)\n",
    "    return data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Sk_-cl3iUjV"
   },
   "outputs": [],
   "source": [
    "def (y_train, y_test):\n",
    "    one_hot_trans = OneHotEncoder().fit(y_train[:, np.newaxis])\n",
    "    return one_hot_trans.transform(y_train[:, np.newaxis]).toarray(), one_hot_trans.transform(y_test[:, np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drM-FP2jiXoF"
   },
   "outputs": [],
   "source": [
    "# 减去行均值\n",
    "def mean_wise(X):\n",
    "    return (X.T - np.mean(X, axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0770124  -0.33174871  0.35002803  1.33668989 -0.81301079]\n",
      " [ 1.15921851  1.02782537  0.57484233 -1.56171812 -0.24830554]\n",
      " [ 0.72192298 -0.07461234 -0.06171017  0.59693475 -0.89229471]\n",
      " [-0.9619392   0.28028597  2.69606356  1.91827587 -1.59256956]\n",
      " [-0.95785167 -0.70939964 -0.51972874  0.44336478 -0.99823236]]\n",
      "[[ 0.0770124   1.15921851  0.72192298 -0.9619392  -0.95785167]\n",
      " [-0.33174871  1.02782537 -0.07461234  0.28028597 -0.70939964]\n",
      " [ 0.35002803  0.57484233 -0.06171017  2.69606356 -0.51972874]\n",
      " [ 1.33668989 -1.56171812  0.59693475  1.91827587  0.44336478]\n",
      " [-0.81301079 -0.24830554 -0.89229471 -1.59256956 -0.99823236]]\n",
      "[ 0.12379416  0.19037251  0.0580481   0.46802333 -0.54836953]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=np.random.randn(5,5)\n",
    "print(X)\n",
    "print(X.T)\n",
    "print(np.mean(X, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9unVSh6NINkP"
   },
   "source": [
    "**Principal Component Analysis for Optimized Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSheEJ9fibF1"
   },
   "outputs": [],
   "source": [
    "def pca(X_train, X_test, n):\n",
    "    pca_trans = PCA(n_components=n).fit(X_train)\n",
    "    return pca_trans.transform(X_train), pca_trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lraJ7zHjyt2e"
   },
   "source": [
    "**Analyzing Various Machine Learning Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5tBV5voEiekV"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qk0nPc6Dy4af"
   },
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzNuEACjiiA2"
   },
   "outputs": [],
   "source": [
    "def dt(criterion=\"entropy\", max_features=\"sqrt\"):\n",
    "    return DecisionTreeClassifier(criterion=criterion, max_features=max_features, max_depth=None, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hazypO0zCwP"
   },
   "source": [
    "**Random Forest Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMrTs8KoilXu"
   },
   "outputs": [],
   "source": [
    "def rf(n_tree=100, max_features=\"sqrt\"):\n",
    "    return RandomForestClassifier(n_estimators=n_tree, max_features=max_features, min_samples_split=2, \\\n",
    "                                  max_depth=None, bootstrap=True, oob_score=False, random_state=0, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kjvr4aCJzMc8"
   },
   "source": [
    "**Gradient Boosting Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSrFiKg6inw1"
   },
   "outputs": [],
   "source": [
    "def gbdt(n_tree=100, max_features=\"sqrt\"):\n",
    "    return GradientBoostingClassifier(n_estimators=n_tree, learning_rate=0.005, \\\n",
    "                                      max_features=max_features, max_depth=None, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIPB4ULRzYLG"
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TObK0n1oiqwt"
   },
   "outputs": [],
   "source": [
    "def logit(C=1.0):\n",
    "    return LogisticRegression(C=1.0, solver=\"lbfgs\", max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDOcVlbZ0DyH"
   },
   "source": [
    "**Multi-layer Perceptron Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qNUrR6QFitGu"
   },
   "outputs": [],
   "source": [
    "def mlp(hidden=(100), act=\"logistic\", batch=32):\n",
    "    return MLPClassifier(hidden_layer_sizes=hidden, activation=act, solver=\"sgd\", batch_size=batch, \\\n",
    "                         learning_rate=\"constant\", learning_rate_init=0.1, early_stopping=False, max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JQ53ALJvCbLP"
   },
   "source": [
    "**Support Vector Machine Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyQsAp1V0Pcf"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?export=view&id=1ABtElBwMDn1dmSOenCGok6i5rhsaq4Ql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEAsvZ5iiwjk"
   },
   "outputs": [],
   "source": [
    "def svm(C=1.0, kernel=\"rbf\"):\n",
    "    return SVC(C=C, kernel=kernel, max_iter=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXmNhiwe0WHW"
   },
   "source": [
    "**K Nearest Neighbours Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyFO4JwVi15N"
   },
   "outputs": [],
   "source": [
    "def knn(n_neighbors=10, weights=\"distance\"):\n",
    "    return KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6vUw42D0h9s"
   },
   "source": [
    "**Naive Bayes Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW1Em8c6i4R8"
   },
   "outputs": [],
   "source": [
    "def bayes():\n",
    "    return GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Am6qP2aN0rd0"
   },
   "source": [
    "**Trainer Fuction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdX5EV74i7Qd"
   },
   "outputs": [],
   "source": [
    "def train(X, y, classifier):\n",
    "    return classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Df-y3hxS0vhm"
   },
   "source": [
    "**Testing Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfdBkPVKi9nk"
   },
   "outputs": [],
   "source": [
    "def test(X, classifier):\n",
    "    return classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhwEiL5m02J1"
   },
   "source": [
    "**Accuracy Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWUJS3YMi_wE"
   },
   "outputs": [],
   "source": [
    "def acc(X, y, classifier):\n",
    "    return classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JziS0Uol1Au8"
   },
   "source": [
    "**Implementation of Algorithms real time in order to find the most optimized solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTUW-zbFjCaN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgISV6Bf1La1"
   },
   "source": [
    "*Let's load the processed M-STAR dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "Qbm2lAWajFQs",
    "outputId": "d57895d1-0867-402f-a57a-83988bbfe223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... \n",
      "------ train ------\n",
      "2S1 274\n",
      "SN_132 232\n",
      "BRDM_2 274\n",
      "BTR_60 195\n",
      "SN_9563 233\n",
      "D7 274\n",
      "T62 273\n",
      "SN_C71 233\n",
      "ZIL131 274\n",
      "ZSU_23_4 274\n",
      "------ test ------\n",
      "2S1 299\n",
      "SN_132 196\n",
      "BRDM_2 298\n",
      "BTR_60 256\n",
      "SN_9563 195\n",
      "D7 299\n",
      "T62 299\n",
      "SN_C71 196\n",
      "ZIL131 299\n",
      "ZSU_23_4 299\n",
      "(2536, 5184) (2536,) (2636, 5184) (2636,)\n"
     ]
    }
   ],
   "source": [
    "print(\"loading ... \")\n",
    "X_train, y_train = get_mstar_data(\"train\", 100, 100, 72)\n",
    "X_test, y_test = get_mstar_data(\"test\", 100, 100, 72)\n",
    "X_train = np.reshape(X_train, [X_train.shape[0], X_train.shape[1] * X_train.shape[2]])\n",
    "X_test = np.reshape(X_test, [X_test.shape[0], X_test.shape[1] * X_test.shape[2]])\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEWH9fBX1ZLM"
   },
   "source": [
    "*Shuffling the loaded dataset to eliminate any bias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DeWdKdt9jIi9",
    "outputId": "0b09c09b-6bc7-4b45-fe18-603ca8e997e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffling ... \n"
     ]
    }
   ],
   "source": [
    "print(\"shuffling ... \")\n",
    "X_train, y_train = data_shuffle(X_train, y_train)\n",
    "X_test, y_test = data_shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDp06Ipi1hZn"
   },
   "source": [
    "*Preprocessing the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gem5U7RoxFv_",
    "outputId": "95568cc5-599b-4f9e-fb8f-e126ecea474b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing ...\n",
      "[[ 0.03944565  0.08650448  0.00415154 ... -0.16055435 -0.04290729\n",
      "  -0.18016219]\n",
      " [ 0.0757005   0.05217108 -0.0497897  ... -0.13998578 -0.10861323\n",
      "  -0.08900539]\n",
      " [ 0.09396711 -0.07073877 -0.1177976  ... -0.05113093 -0.19622897\n",
      "  -0.10211132]\n",
      " ...\n",
      " [-0.21021393  0.09174685  0.24468803 ... -0.19844923  0.16233509\n",
      "   0.19762921]\n",
      " [ 0.04450042 -0.01432311 -0.22608781 ... -0.02608781 -0.09667605\n",
      "  -0.13197016]\n",
      " [ 0.04343379 -0.16048778  0.06304164 ...  0.14539458 -0.01538974\n",
      "  -0.0820564 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"preprocessing ...\")\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = mean_wise(X_train)\n",
    "X_test = mean_wise(X_test)\n",
    "print(X_train)\n",
    "X_train, X_test = pca(X_train, X_test, 80)\n",
    "\n",
    "# y_train, y_test = one_hot(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.37967693e-04 -1.53353619e-02 -1.05917483e-03 ... -9.97725139e-04\n",
      "   1.64346221e-03  1.56938264e-17]\n",
      " [ 2.14723636e-02  1.75083076e-02  1.35477782e-03 ... -1.18781432e-04\n",
      "  -3.78044225e-03 -2.39608680e-17]\n",
      " [-1.60864097e-02 -2.11139627e-03 -1.23877131e-02 ... -1.13849091e-03\n",
      "   8.62520018e-04 -6.77626358e-20]\n",
      " ...\n",
      " [-1.34575246e-02 -2.36927495e-02  1.54040468e-02 ... -8.24669339e-04\n",
      "   2.18930912e-05  2.48485585e-17]\n",
      " [-1.29196537e-02  1.75324883e-02  2.36264421e-03 ...  1.71924344e-04\n",
      "   1.06671989e-03 -1.96782694e-17]\n",
      " [ 5.37434625e-03  1.57120214e-02  7.99840812e-03 ... -2.22214175e-03\n",
      "   1.70611602e-03 -1.94614290e-17]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owaJixtu10Iu"
   },
   "source": [
    "*Finally Training the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R0yEQFMpxOTz",
    "outputId": "2bd97ed2-88d5-4652-ce7c-9b9bb9c2a35f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n"
     ]
    }
   ],
   "source": [
    "print(\"training ...\")\n",
    "# classifier = train(X_train, y_train, dt(\"entropy\", 0.8)) # 70.68%\n",
    "# classifier = train(X_train, y_train, rf(1000, \"sqrt\")) # 96.49%\n",
    "# classifier = train(X_train, y_train, gbdt(1000, \"sqrt\")) # 95.17%\n",
    "# classifier = train(X_train, y_train, logit(1.0))    # 90.14%\n",
    "# classifier = train(X_train, y_train, mlp(1000, \"logistic\"))   # 93.36%\n",
    "classifier = train(X_train, y_train, svm(1.0, \"rbf\"))     # 96.82%\n",
    "# classifier = train(X_train, y_train, knn(10, \"uniform\"))   # 95.34%\n",
    "# classifier = train(X_train, y_train, svm())   # 97.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3V5CtQS2DM2"
   },
   "source": [
    "*As seen while analyzing the above algorithms, Support Vector machine was able to provide higest accuracy for determining the vehicle images from the test data, that is 97.8% accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BSZGPQRoxj4h",
    "outputId": "90763604-c30c-48ea-849f-081bcb2a52e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing ...\n",
      "0.9988170347003155\n",
      "0.9810318664643399\n"
     ]
    }
   ],
   "source": [
    "print(\"testing ...\")\n",
    "print(acc(X_train, y_train, classifier))\n",
    "print(acc(X_test, y_test, classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmjN0SNS3LMA"
   },
   "source": [
    "**The END**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0Rsh1NhIeem"
   },
   "source": [
    "**Thank You**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_21C02",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
