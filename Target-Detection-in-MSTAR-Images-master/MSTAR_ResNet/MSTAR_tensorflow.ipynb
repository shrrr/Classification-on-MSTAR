{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyP1jJAreqjC7QB+AXgy4ZO/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NMqGbWaVqRO7"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_A-nLfuPqTLQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612094043341,"user_tz":-480,"elapsed":23913,"user":{"displayName":"孙浩然","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimb8aLg-3WQRJeS5sCo0IQ-bWLOLMCzP-AN-9e=s64","userId":"16490380538315503196"}},"outputId":"8ad35a34-4bfb-4798-a715-7918c9c273c3"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NEL8tzw6qT--","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612094046225,"user_tz":-480,"elapsed":1302,"user":{"displayName":"孙浩然","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimb8aLg-3WQRJeS5sCo0IQ-bWLOLMCzP-AN-9e=s64","userId":"16490380538315503196"}},"outputId":"7efd3b64-d867-447c-a71c-c8696814e4d0"},"source":["cd MyDrive/TargetClassify/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/gdrive/MyDrive/TargetClassify\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcffzouosD5Q","executionInfo":{"status":"ok","timestamp":1612094049854,"user_tz":-480,"elapsed":1188,"user":{"displayName":"孙浩然","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimb8aLg-3WQRJeS5sCo0IQ-bWLOLMCzP-AN-9e=s64","userId":"16490380538315503196"}},"outputId":"1b7f3083-bb56-4311-e847-b9ecc10acba0"},"source":["ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mDataSet\u001b[0m/\n","DataSet.zip\n","model.pth\n","resnet50_weights_tf_dim_ordering_tf_kernels_notop1.h5\n","resnet50_weights_tf_dim_ordering_tf_kernels_notop2.h5\n","resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","resnet50_weights_tf_dim_ordering_tf_kernels_notop.zip\n","Untitled\n","Untitled.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEJoNRJ2sJgl","executionInfo":{"status":"ok","timestamp":1612094065701,"user_tz":-480,"elapsed":13658,"user":{"displayName":"孙浩然","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimb8aLg-3WQRJeS5sCo0IQ-bWLOLMCzP-AN-9e=s64","userId":"16490380538315503196"}},"outputId":"32cfa002-0fe5-46ae-ac4a-f55ee0222a64"},"source":["\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense,Input\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import VGG16, ResNet50\n","from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","import numpy as np\n","from keras import backend as K\n","from keras.models import Model\n","from keras.callbacks import EarlyStopping\n","from keras.models import load_model\n","\n","\n","K.set_image_data_format('channels_first')\n","img_width, img_height = 200,200\n","\n","\n","input_tensor = Input(shape=(3,img_width, img_height))\n","model = ResNet50(include_top=False, weights=None, input_tensor=input_tensor)\n","print('Model loaded.')\n","model.load_weights(WEIGHTS_PATH_NO_TOP)\n","\n","\n","x = model.output\n","x = Flatten()(x)\n","x = Dense(256,activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(10, activation = 'softmax')(x)\n","\n","model2 = Model(inputs=model.input, outputs=x)\n","\n","\n","for layer in model2.layers[:45]: # set the first 11 layers(fine tune conv4 and conv5 block can also further improve accuracy\n","    layer.trainable = False\n","model2.compile(loss='binary_crossentropy',\n","              optimizer = SGD(lr=1e-3,momentum=0.9),\n","              metrics=['accuracy'])\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GjxPQe1fsYCA","executionInfo":{"status":"error","timestamp":1612098447382,"user_tz":-480,"elapsed":2894722,"user":{"displayName":"孙浩然","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimb8aLg-3WQRJeS5sCo0IQ-bWLOLMCzP-AN-9e=s64","userId":"16490380538315503196"}},"outputId":"d3302752-978c-46a5-dab2-927a4b2b9c4a"},"source":["train_data_dir = './DataSet/test'\n","validation_data_dir = './DataSet/train'\n","\n","nb_train_samples = 2536\n","nb_validation_samples = 2636\n","epochs = 200\n","batch_size = 32\n","\n","\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        rotation_range=10.,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 图片generator\n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_height, img_width),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_height, img_width),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n","\n","model2.fit_generator(\n","        train_generator,\n","        steps_per_epoch=nb_train_samples // batch_size,\n","        epochs=epochs,\n","        validation_data=validation_generator,\n","        validation_steps=nb_validation_samples // batch_size)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Found 2636 images belonging to 10 classes.\n","Found 2536 images belonging to 10 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/200\n","79/79 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.3042WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 523s 7s/step - loss: 0.3080 - accuracy: 0.3042 - val_loss: 0.3553 - val_accuracy: 0.1341\n","Epoch 2/200\n","79/79 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.5048WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 35s 442ms/step - loss: 0.2418 - accuracy: 0.5048 - val_loss: 0.3569 - val_accuracy: 0.1830\n","Epoch 3/200\n","79/79 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.6412WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 34s 433ms/step - loss: 0.1891 - accuracy: 0.6412 - val_loss: 0.3518 - val_accuracy: 0.2275\n","Epoch 4/200\n","79/79 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.7294WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 34s 425ms/step - loss: 0.1517 - accuracy: 0.7294 - val_loss: 0.2455 - val_accuracy: 0.5134\n","Epoch 5/200\n","79/79 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.8138WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 411ms/step - loss: 0.1138 - accuracy: 0.8138 - val_loss: 0.1577 - val_accuracy: 0.6968\n","Epoch 6/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.8684WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 410ms/step - loss: 0.0899 - accuracy: 0.8684 - val_loss: 0.0860 - val_accuracy: 0.8580\n","Epoch 7/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.8975WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 411ms/step - loss: 0.0695 - accuracy: 0.8975 - val_loss: 0.0712 - val_accuracy: 0.8667\n","Epoch 8/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9107WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 405ms/step - loss: 0.0617 - accuracy: 0.9107 - val_loss: 0.1264 - val_accuracy: 0.7823\n","Epoch 9/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9199WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 401ms/step - loss: 0.0548 - accuracy: 0.9199 - val_loss: 0.0829 - val_accuracy: 0.8576\n","Epoch 10/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9399WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 410ms/step - loss: 0.0432 - accuracy: 0.9399 - val_loss: 0.1291 - val_accuracy: 0.7800\n","Epoch 11/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9537WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 398ms/step - loss: 0.0345 - accuracy: 0.9537 - val_loss: 0.1122 - val_accuracy: 0.7906\n","Epoch 12/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9617WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 393ms/step - loss: 0.0331 - accuracy: 0.9617 - val_loss: 0.0705 - val_accuracy: 0.8718\n","Epoch 13/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9585WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 399ms/step - loss: 0.0332 - accuracy: 0.9585 - val_loss: 0.0748 - val_accuracy: 0.8612\n","Epoch 14/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9633WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 395ms/step - loss: 0.0282 - accuracy: 0.9633 - val_loss: 0.1181 - val_accuracy: 0.8064\n","Epoch 15/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9673WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 398ms/step - loss: 0.0305 - accuracy: 0.9673 - val_loss: 0.3687 - val_accuracy: 0.4673\n","Epoch 16/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9709WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 389ms/step - loss: 0.0218 - accuracy: 0.9709 - val_loss: 0.1506 - val_accuracy: 0.7717\n","Epoch 17/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9713WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 392ms/step - loss: 0.0232 - accuracy: 0.9713 - val_loss: 0.0597 - val_accuracy: 0.9014\n","Epoch 18/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9805WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 389ms/step - loss: 0.0183 - accuracy: 0.9805 - val_loss: 0.1162 - val_accuracy: 0.7930\n","Epoch 19/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9789WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 390ms/step - loss: 0.0173 - accuracy: 0.9789 - val_loss: 0.0237 - val_accuracy: 0.9661\n","Epoch 20/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9844WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 392ms/step - loss: 0.0140 - accuracy: 0.9844 - val_loss: 0.0612 - val_accuracy: 0.9184\n","Epoch 21/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9876WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 400ms/step - loss: 0.0124 - accuracy: 0.9876 - val_loss: 0.3361 - val_accuracy: 0.5099\n","Epoch 22/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9809WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 391ms/step - loss: 0.0147 - accuracy: 0.9809 - val_loss: 0.0366 - val_accuracy: 0.9416\n","Epoch 23/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9844WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 400ms/step - loss: 0.0150 - accuracy: 0.9844 - val_loss: 0.0395 - val_accuracy: 0.9369\n","Epoch 24/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9844WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 393ms/step - loss: 0.0133 - accuracy: 0.9844 - val_loss: 0.0959 - val_accuracy: 0.8450\n","Epoch 25/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9884WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 402ms/step - loss: 0.0108 - accuracy: 0.9884 - val_loss: 0.0632 - val_accuracy: 0.9085\n","Epoch 26/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9916WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 397ms/step - loss: 0.0092 - accuracy: 0.9916 - val_loss: 0.0687 - val_accuracy: 0.8987\n","Epoch 27/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9888WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 395ms/step - loss: 0.0104 - accuracy: 0.9888 - val_loss: 0.1233 - val_accuracy: 0.8013\n","Epoch 28/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9852WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 393ms/step - loss: 0.0126 - accuracy: 0.9852 - val_loss: 0.0625 - val_accuracy: 0.8979\n","Epoch 29/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9904WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 392ms/step - loss: 0.0085 - accuracy: 0.9904 - val_loss: 0.0202 - val_accuracy: 0.9688\n","Epoch 30/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9924WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 400ms/step - loss: 0.0084 - accuracy: 0.9924 - val_loss: 0.2311 - val_accuracy: 0.6853\n","Epoch 31/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9920WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 401ms/step - loss: 0.0113 - accuracy: 0.9920 - val_loss: 0.0708 - val_accuracy: 0.9006\n","Epoch 32/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9968WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 397ms/step - loss: 0.0060 - accuracy: 0.9968 - val_loss: 0.0124 - val_accuracy: 0.9830\n","Epoch 33/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9928WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 397ms/step - loss: 0.0082 - accuracy: 0.9928 - val_loss: 0.0731 - val_accuracy: 0.8876\n","Epoch 34/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9924WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 405ms/step - loss: 0.0075 - accuracy: 0.9924 - val_loss: 0.1004 - val_accuracy: 0.8383\n","Epoch 35/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9888WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 396ms/step - loss: 0.0083 - accuracy: 0.9888 - val_loss: 0.3246 - val_accuracy: 0.6144\n","Epoch 36/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9940WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 397ms/step - loss: 0.0068 - accuracy: 0.9940 - val_loss: 0.2616 - val_accuracy: 0.5804\n","Epoch 37/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9928WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 392ms/step - loss: 0.0066 - accuracy: 0.9928 - val_loss: 0.1796 - val_accuracy: 0.7835\n","Epoch 38/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9940WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 390ms/step - loss: 0.0054 - accuracy: 0.9940 - val_loss: 0.0675 - val_accuracy: 0.9010\n","Epoch 39/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9928WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 385ms/step - loss: 0.0059 - accuracy: 0.9928 - val_loss: 0.0159 - val_accuracy: 0.9775\n","Epoch 40/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9944WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 395ms/step - loss: 0.0060 - accuracy: 0.9944 - val_loss: 0.0720 - val_accuracy: 0.8987\n","Epoch 41/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9956WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 385ms/step - loss: 0.0048 - accuracy: 0.9956 - val_loss: 0.0490 - val_accuracy: 0.9322\n","Epoch 42/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9936WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 389ms/step - loss: 0.0060 - accuracy: 0.9936 - val_loss: 0.1184 - val_accuracy: 0.8245\n","Epoch 43/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9972WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 384ms/step - loss: 0.0046 - accuracy: 0.9972 - val_loss: 0.0095 - val_accuracy: 0.9850\n","Epoch 44/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9956WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 387ms/step - loss: 0.0043 - accuracy: 0.9956 - val_loss: 0.1910 - val_accuracy: 0.7827\n","Epoch 45/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9936WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 384ms/step - loss: 0.0058 - accuracy: 0.9936 - val_loss: 0.0221 - val_accuracy: 0.9696\n","Epoch 46/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9956WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 383ms/step - loss: 0.0048 - accuracy: 0.9956 - val_loss: 0.0352 - val_accuracy: 0.9487\n","Epoch 47/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9944WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 381ms/step - loss: 0.0058 - accuracy: 0.9944 - val_loss: 0.0174 - val_accuracy: 0.9783\n","Epoch 48/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9964WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 386ms/step - loss: 0.0047 - accuracy: 0.9964 - val_loss: 0.1343 - val_accuracy: 0.8245\n","Epoch 49/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9936WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 383ms/step - loss: 0.0058 - accuracy: 0.9936 - val_loss: 0.3211 - val_accuracy: 0.6353\n","Epoch 50/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9912WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 388ms/step - loss: 0.0070 - accuracy: 0.9912 - val_loss: 0.0421 - val_accuracy: 0.9432\n","Epoch 51/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9932WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 392ms/step - loss: 0.0060 - accuracy: 0.9932 - val_loss: 0.0427 - val_accuracy: 0.9373\n","Epoch 52/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9976WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 31s 391ms/step - loss: 0.0040 - accuracy: 0.9976 - val_loss: 0.0192 - val_accuracy: 0.9724\n","Epoch 53/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9968WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 379ms/step - loss: 0.0032 - accuracy: 0.9968 - val_loss: 0.0135 - val_accuracy: 0.9787\n","Epoch 54/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9988WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 382ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.0141 - val_accuracy: 0.9771\n","Epoch 55/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9952WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 377ms/step - loss: 0.0046 - accuracy: 0.9952 - val_loss: 0.0152 - val_accuracy: 0.9787\n","Epoch 56/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9964WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 386ms/step - loss: 0.0038 - accuracy: 0.9964 - val_loss: 0.0097 - val_accuracy: 0.9890\n","Epoch 57/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9976WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 382ms/step - loss: 0.0033 - accuracy: 0.9976 - val_loss: 0.0139 - val_accuracy: 0.9807\n","Epoch 58/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9952WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 385ms/step - loss: 0.0057 - accuracy: 0.9952 - val_loss: 0.0310 - val_accuracy: 0.9586\n","Epoch 59/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9976WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 30s 384ms/step - loss: 0.0030 - accuracy: 0.9976 - val_loss: 0.1245 - val_accuracy: 0.8316\n","Epoch 60/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9956WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 405ms/step - loss: 0.0044 - accuracy: 0.9956 - val_loss: 0.1695 - val_accuracy: 0.7610\n","Epoch 61/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9936WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 411ms/step - loss: 0.0054 - accuracy: 0.9936 - val_loss: 0.0398 - val_accuracy: 0.9412\n","Epoch 62/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9968WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 34s 432ms/step - loss: 0.0036 - accuracy: 0.9968 - val_loss: 0.2247 - val_accuracy: 0.7642\n","Epoch 63/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9984WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 418ms/step - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.0101 - val_accuracy: 0.9870\n","Epoch 64/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9988WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 408ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.0465 - val_accuracy: 0.9397\n","Epoch 65/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9948WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 405ms/step - loss: 0.0058 - accuracy: 0.9948 - val_loss: 0.0598 - val_accuracy: 0.9207\n","Epoch 66/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9936WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 32s 410ms/step - loss: 0.0061 - accuracy: 0.9936 - val_loss: 0.1763 - val_accuracy: 0.7855\n","Epoch 67/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9964WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 422ms/step - loss: 0.0035 - accuracy: 0.9964 - val_loss: 0.0490 - val_accuracy: 0.9365\n","Epoch 68/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9972WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 414ms/step - loss: 0.0031 - accuracy: 0.9972 - val_loss: 0.0518 - val_accuracy: 0.9215\n","Epoch 69/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9980WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 414ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 0.0509 - val_accuracy: 0.9397\n","Epoch 70/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 420ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0421 - val_accuracy: 0.9412\n","Epoch 71/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9984WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 414ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 0.0160 - val_accuracy: 0.9791\n","Epoch 72/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9976WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 412ms/step - loss: 0.0018 - accuracy: 0.9976 - val_loss: 0.0221 - val_accuracy: 0.9696\n","Epoch 73/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9984WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 421ms/step - loss: 0.0016 - accuracy: 0.9984 - val_loss: 0.1004 - val_accuracy: 0.8592\n","Epoch 74/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9980WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 33s 413ms/step - loss: 0.0024 - accuracy: 0.9980 - val_loss: 0.0145 - val_accuracy: 0.9799\n","Epoch 75/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9980WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 82 batches). You may need to use the repeat() function when building your dataset.\n","79/79 [==============================] - 34s 427ms/step - loss: 0.0028 - accuracy: 0.9980 - val_loss: 0.3137 - val_accuracy: 0.6128\n","Epoch 76/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9984"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7bc9f63ba7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         validation_steps=nb_validation_samples // batch_size)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"R94_dhrE1zqe"},"source":[],"execution_count":null,"outputs":[]}]}